---
title: "Feature-based time series analysis"
date: "27 September 2019"
author: "Rob J Hyndman"
toc: true
titlefontsize: 28pt
output:
  binb::monash:
    colortheme: monashwhite
    fig_width: 8
    fig_height: 5
    highlight: tango
    keep_tex: yes
    includes:
      in_header: preamble.tex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE,
  cache = TRUE
)
library(tidyverse)
library(lubridate)
library(tsibble)
library(feasts)
library(patchwork)
savepdf <- function(file, width = 16, height = 10) {
  fname <<- paste("figs/", file, ".pdf", sep = "")
  pdf(fname, width = width / 2.54, height = height / 2.54, pointsize = 10, bg = "white")
  par(mgp = c(2.2, 0.45, 0), tcl = -0.4, mar = c(3.3, 3.6, 1.1, 1.1))
}
endpdf <- function() {
  crop::dev.off.crop(fname)
}
gghist <- function(data, mapping, ...) {
  x <- GGally::eval_data_col(data, mapping$x)
  bw <- 0.2 * bw.nrd0(x) + 0.8 * bw.SJ(x)
  p <- ggplot(data, mapping) +
    geom_density(col = NA, fill = "#cc5900", bw = bw)
  return(p)
}
# Function to produce very basic table, no lines or headings
baretable <- function(tbl, digits = 0,
                      include.colnames=FALSE, include.rownames=FALSE,
                      hline.after=NULL,
                      size = getOption("xtable.size", NULL),
                      add.to.row =  getOption("xtable.add.to.row", NULL),
                      ...) {
  tbl %>%
    xtable::xtable(digits = digits, ...) %>%
    print(
      include.colnames = include.colnames,
      include.rownames = include.rownames,
      hline.after = hline.after,
      comment = FALSE,
      latex.environments = NULL,
      floating = FALSE,
      size=size,
      add.to.row=add.to.row,
      sanitize.text.function = function(x) {
        x
      }
    )
}
set.seed(20190927)
options(digits = 3, width = 63)
```

# Feature-based visualization

## M3 competition: 2000
\full{M3paper}
\only<2>{
\placefig{1}{4}{height=3cm, width=10cm, keepaspectratio=true}{SMakridakis}
\placefig{8.8}{4}{height=3cm, width=10cm, keepaspectratio=true}{MHibon}}


## M3 competition: 2000
\fontsize{13}{14}\sf
\begin{block}{}
``The M3-Competition is a final attempt by the authors to settle the accuracy issue of
various time series methods\dots\ The extension involves the inclusion of more methods/ researchers (in particular in the areas of neural networks and expert systems) and more series.''
\end{block}

  * 3003 series
  * All data from business, demography, finance and economics.
  * Series length between 14 and 126.
  * Either non-seasonal, monthly or quarterly.
  * All time series positive.

## How to plot lots of time series?

```{r m3data, message=FALSE}
m3totsibble <- function(z) {
  rbind(
    as_tsibble(z$x) %>% mutate(Type = "Training"),
    as_tsibble(z$xx) %>% mutate(Type = "Test")
  ) %>%
    mutate(
      st = z$st,
      type = z$type,
      period = z$period,
      description = z$description,
      sn = z$sn,
    ) %>%
    as_tibble()
}
m3yearly <- Mcomp::M3 %>%
  subset("yearly") %>%
  purrr::map_dfr(m3totsibble) %>%
  as_tsibble(index = index, key = c(sn, period, st)) %>%
  mutate(z = scale(value))
m3quarterly <- Mcomp::M3 %>%
  subset("quarterly") %>%
  purrr::map_dfr(m3totsibble) %>%
  mutate(index = yearquarter(index)) %>%
  as_tsibble(index = index, key = c(sn, period, st))
m3monthly <- Mcomp::M3 %>%
  subset("monthly") %>%
  purrr::map_dfr(m3totsibble) %>%
  mutate(index = yearmonth(index)) %>%
  as_tsibble(index = index, key = c(sn, period, st))
m3other <- Mcomp::M3 %>%
  subset("other") %>%
  purrr::map_dfr(m3totsibble) %>%
  as_tsibble(index = index, key = c(sn, period, st))
```

```{r scalem3}
scalem3 <- list()
for (i in seq(3003)) {
  scalem3[[i]] <- Mcomp::M3[[i]]$x - min(Mcomp::M3[[i]]$x)
  scalem3[[i]] <- as.numeric(scalem3[[i]] / max(scalem3[[i]]))
}
k <- sample(1:3003, 3003)
files <- c(1:5, seq(10, 50, by = 10), 100, 200, 500, 3003)
cols <- sample(rainbow(3003))
for (i in files) {
  fname <- paste("M3data", i, sep = "")
  savepdf(fname)
  plot(0, 0, ylim = range(scalem3), xlim = c(0, 1), xlab = "Time", ylab = "", type = "n")
  for (i in 1:i) {
    lines((1:length(scalem3[[k[i]]])) / length(scalem3[[k[i]]]), scalem3[[k[i]]],
      col = cols[i]
    )
  }
  endpdf()
}
```

\only<1>{\full{M3data1}}
\only<2>{\full{M3data2}}
\only<3>{\full{M3data3}}
\only<4>{\full{M3data4}}
\only<5>{\full{M3data5}}
\only<6>{\full{M3data10}}
\only<7>{\full{M3data20}}
\only<8>{\full{M3data30}}
\only<9>{\full{M3data40}}
\only<10>{\full{M3data50}}
\only<11>{\full{M3data100}}
\only<12>{\full{M3data200}}
\only<13>{\full{M3data500}}
\only<14>{\full{M3data3003}}

## Key idea
\placefig{9.1}{.5}{width=3.6cm}{tukey}
\begin{textblock}{3}(9.7,5.4)\small\textit{John W Tukey}\end{textblock}
\begin{textblock}{8}(0.7,1.2)
\begin{alertblock}{Cognostics}
Computer-produced diagnostics\\ (Tukey and Tukey, 1985).
\end{alertblock}
\end{textblock}\pause
\vspace*{2.5cm}

\alert{Examples for time series}

  * lag correlation
  * size and direction of trend
  * strength of seasonality
  * timing of peak seasonality
  * spectral entropy

\vspace*{0.3cm}
\begin{block}{}
Called ``features'' in the machine learning literature.
\end{block}

## An STL decomposition: N2096
\begin{alertblock}{}
\centerline{$Y_t = S_t + T_t + R_t$\qquad $S_{t}$ is periodic with mean 0}
\end{alertblock}

```{r stl, fig.height=4.7}
m3monthly %>%
  filter(sn == "N2096") %>%
  STL(value) %>%
  autoplot() + ylab("") + xlab("") +
  scale_x_date(
    breaks = seq(as_date("1982-01-01"), as_date("1993-01-01"), by = "year"),
    labels = 1982:1993, minor_breaks = NULL
  )
```

## Candidate features

\begin{block}{STL decomposition}
\centerline{$Y_t = S_t + T_t + R_t$}
\end{block}\pause\fontsize{14}{16}\sf\vspace*{-0.2cm}

* Seasonal period
* Autocorrelations of data ($Y_1,\dots,Y_T$)
* Autocorrelations of data ($R_1,\dots,R_T$)
* Strength of seasonality: $\max\left(0,1 - \frac{\Var(R_t)}{\Var(Y_t-T_t)}\right)$
* Strength of trend:  $\max\left(0,1 - \frac{\Var(R_t)}{\Var(Y_t-S_t)}\right)$
* Spectral entropy: $H = - \int_{-\pi}^{\pi} f_y(\lambda) \log f_y(\lambda) d\lambda$, where $f_y(\lambda)$ is spectral density of $Y_t$.\newline
Low values of $H$ suggest a time series that is easier to forecast (more signal).
* Optimal Box-Cox transformation of data

## Feature properties
\fontsize{13}{14.5}\sf

\begin{block}{}
For series with different lengths, scales, domains, etc., we need features that are:
\begin{itemize}\tightlist
\item scale-independent
\item ergodic
\end{itemize}
\end{block}\pause

1. Seasonal period
2. Strength of seasonality
3. Strength of trend
4. First autocorrelation of STL remainder series
5. Spectral entropy
6. Optimal MLE Box-Cox transformation of data\pause

###
For other analyses, it may be appropriate to have different requirements.

```{r m3_features}
khs_stl <- function(x, period) {
  output <- c(n = length(x), frequency = period, feat_spectral(x))
  lambda <- forecast::BoxCox.lambda(ts(x, frequency = period),
    lower = 0, upper = 1, method = "loglik"
  )
  stlfeatures <- feat_stl(box_cox(x, lambda),
    .period = period,
    s.window = "periodic", robust = TRUE
  )
  output <- c(output, stlfeatures, lambda = lambda)
  if (period == 1L) {
    output <- c(output, seasonal_strength = 0)
  }
  return(output)
}
m3_features <- bind_rows(
  m3yearly %>% features(value, features = list(~ khs_stl(., 1))),
  m3quarterly %>% features(value, features = list(~ khs_stl(., 4))) %>%
    rename(seasonal_strength = seasonal_strength_4),
  m3monthly %>% features(value, features = list(~ khs_stl(., 12))) %>%
    rename(seasonal_strength = seasonal_strength_12),
  m3other %>% features(value, features = list(~ khs_stl(., 1)))
) %>%
  select(
    sn, n, spectral_entropy, trend_strength, seasonal_strength,
    frequency, stl_e_acf1, lambda
  )
```

```{r M3examples, include=FALSE, dependson="M3Features"}
m3plot <- function(sn) {
  m3totsibble(Mcomp::M3[[sn[1]]]) %>%
    as_tsibble(index = index, key = c(sn, period, st)) %>%
    autoplot(value) + ylab(sn) + xlab("")
}
# Consider only long series for plotting
m3_long <- m3_features %>% filter(n > 50)
fnames <- m3_long %>%
  select(-n, -sn) %>%
  colnames()
for (i in seq_along(fnames)) {
  savepdf(paste(fnames[i], "Lo", sep = ""), width = 20, height = 7)
  m3_long %>%
    filter(m3_long[, fnames[i]] == min(m3_long[, fnames[i]])) %>%
    pull(sn) %>%
    m3plot() %>%
    print()
  endpdf()
  savepdf(paste(fnames[i], "Hi", sep = ""), width = 20, height = 7)
  m3_long %>%
    filter(m3_long[, fnames[i]] == max(m3_long[, fnames[i]])) %>%
    pull(sn) %>%
    m3plot() %>%
    print()
  endpdf()
}
```

## Distribution of Period for M3

```{r M3period, dependson="M3Features"}
m3_features %>%
  GGally::ggally_barDiag(
    mapping = aes(frequency),
    binwidth = 0.2, colour = "#cc5900", fill = "#cc5900"
  ) +
  scale_x_continuous(breaks = seq(12), minor_breaks = NULL)
```

## Distribution of Seasonality for M3

```{r M3season, dependson="M3Features"}
m3_features %>% gghist(aes(x = seasonal_strength))
```

\only<2->{
\begin{textblock}{6}(0.2,3)
  \begin{alertblock}{Low Seasonality}
    \includegraphics[width=6cm]{seasonal_strengthLo.pdf}
  \end{alertblock}
\end{textblock}
}
\only<3>{
\begin{textblock}{6}(6.6,3)
  \begin{alertblock}{High Seasonality}
    \includegraphics[width=6cm]{seasonal_strengthHi.pdf}
  \end{alertblock}
\end{textblock}
}

## Distribution of Trend for M3

```{r M3trend, dependson="M3Features"}
m3_features %>% gghist(aes(x = trend_strength))
```

\only<2->{
\begin{textblock}{6}(0.2,3)
  \begin{alertblock}{Low Trend}
    \includegraphics[width=6cm]{trend_strengthLo.pdf}
  \end{alertblock}
\end{textblock}
}
\only<3>{
\begin{textblock}{6}(6.6,3)
  \begin{alertblock}{High Trend}
    \includegraphics[width=6cm]{trend_strengthHi.pdf}
  \end{alertblock}
\end{textblock}
}

## Distribution of Residual ACF1 for M3

```{r M3ACF1, dependson="M3Features"}
m3_features %>% gghist(aes(x = stl_e_acf1))
```

\only<2->{
\begin{textblock}{6}(0.2,3)
  \begin{alertblock}{Low ACF1}
    \includegraphics[width=6cm]{stl_e_acf1Lo.pdf}
  \end{alertblock}
\end{textblock}
}
\only<3>{
\begin{textblock}{6}(6.6,3)
  \begin{alertblock}{High ACF1}
    \includegraphics[width=6cm]{stl_e_acf1Hi.pdf}
  \end{alertblock}
\end{textblock}
}

## Distribution of Spectral Entropy for M3

```{r M3entropy, dependson="M3Features"}
m3_features %>% gghist(aes(x = spectral_entropy))
```

\only<2->{
\begin{textblock}{6}(0.2,3)
  \begin{alertblock}{Low Entropy}
    \includegraphics[width=6cm]{spectral_entropyLo.pdf}
  \end{alertblock}
\end{textblock}
}
\only<3>{
\begin{textblock}{6}(6.6,3)
  \begin{alertblock}{High Entropy}
    \includegraphics[width=6cm]{spectral_entropyHi.pdf}
  \end{alertblock}
\end{textblock}
}

## Feature distributions

```{r ACF1SE, dependson="M3Features"}
m3_features %>%
  ggplot(aes(x = spectral_entropy, y = stl_e_acf1)) +
  geom_point()
```

## Feature distributions

```{r TrendSE, dependson="M3Features"}
m3_features %>%
  ggplot(aes(x = spectral_entropy, y = trend_strength)) +
  geom_point()
```

## Feature distributions

```{r M3pairs, dependson="M3Features", message=FALSE}
library(GGally)
# Fig 1 of paper
yk_ggally_densityDiag <- wrap(gghist, adjust = 0.5)
yk_ggally_barDiag <- wrap(ggally_barDiag,
  colour = "#cc5900",
  fill = "#cc5900", width = 0.2
)
m3_features %>%
  mutate(period = as.character(frequency)) %>%
  select(period, spectral_entropy, trend_strength, seasonal_strength, stl_e_acf1, lambda) %>%
  GGally::ggpairs(
    diag = list(
      continuous = yk_ggally_densityDiag,
      discrete = yk_ggally_barDiag
    ),
    axisLabels = "none",
    lower = list(continuous = wrap("points", alpha = 0.5, size = 0.2))
  ) -> p
print(p)
savepdf("PairwisePlot")
print(p)
endpdf()
```

## Dimension reduction for time series

```{r m3sample, include=FALSE, dependson='scalem3'}
j <- sample(1:3003, 100)
ncol <- 5
n <- length(j)
savepdf("M3sample")
plot(0, 0, ylim = c(0, n / ncol), xlim = c(0, ncol * 1.2), yaxt = "n", xaxt = "n", ylab = "", xlab = "", bty = "n", type = "n")
for (i in 1:n) {
  lines(
    (1:length(scalem3[[j[i]]])) / length(scalem3[[j[i]]]) + ((i - 1) %% ncol) * 1.1,
    scalem3[[j[i]]] + trunc((i - 1) / ncol)
  )
}
endpdf()
```

```{r m3pca, dependson="M3Features"}
# 2-d Feature space (Top of Fig 2)
khs_pca <- m3_features %>%
  select(-sn, -n) %>%
  prcomp(scale = TRUE)
khs_pca$x[, 2] <- -khs_pca$x[, 2]
khs_pca$rotation[, 2] <- -khs_pca$rotation[, 2]
khs_pca %>%
  augment(m3_features) %>%
  ggplot(aes(x = .fittedPC1, y = .fittedPC2)) +
  geom_point() -> p
savepdf("FeatureSpace", height = 13, width = 13)
print(p)
endpdf()
```

\only<1->{\placefig{0}{1}{width=4cm,height=8.3cm,trim=0 0 200 0,clip=TRUE}{M3sample}}
\only<2->{\placefig{6}{1}{width=6cm}{PairwisePlot}}
\only<3>{\placefig{5.2}{5.3}{width=5cm}{FeatureSpace}}

\only<2->{\placefig{4}{2}{width=2cm}{arrow}}
\only<3>{\placefig{8.4}{4.2}{width=2cm,angle=-90}{arrow}}

\only<2->{\begin{textblock}{2.1}(4,2.6)
\begin{alertblock}{}\small
Feature calculation
\end{alertblock}
\end{textblock}}

\only<3->{\begin{textblock}{2.8}(9.7,4.1)
\begin{alertblock}{}\small
Principal component decomposition
\end{alertblock}
\end{textblock}}

## M3 feature space
\fontsize{11}{11}\sf

\vspace*{-0.2cm}

\hspace*{-0.5cm}\includegraphics[width=8.4cm]{FeatureSpace}

\begin{textblock}{4}(8.3,3)
\begin{block}{}\fontsize{12}{13}\sf
First two PCs explain 58.5\% of the variance.
\end{block}
\end{textblock}

## M3 feature space

```{r m3pca1, dependson="m3pca", fig.height=5}
p + geom_point(aes(color = factor(frequency))) +
  coord_equal(ratio = 1) + scale_color_viridis_d() +
  guides(colour = guide_legend("Frequency  "))
```

## M3 feature space

```{r m3pca2, dependson="m3pca", fig.height=5}
p + geom_point(aes(color = seasonal_strength)) +
  coord_equal(ratio = 1) +
  scale_color_viridis_c() +
  guides(colour = guide_legend("Seasonality"))
```

## M3 feature space

```{r m3pca3, dependson="m3pca", fig.height=5}
p + geom_point(aes(color = trend_strength)) +
  coord_equal(ratio = 1) +
  scale_color_viridis_c() +
  guides(colour = guide_legend("Trend        "))
```

## M3 feature space

```{r m3pca4, dependson="m3pca", fig.height=5}
p + geom_point(aes(color = spectral_entropy)) +
  coord_equal(ratio = 1) +
  scale_color_viridis_c() +
  guides(colour = guide_legend("Entropy    "))
```

## M3 feature space

```{r m3pca5, dependson="m3pca", fig.height=5}
p + geom_point(aes(color = stl_e_acf1)) +
  coord_equal(ratio = 1) +
  scale_color_viridis_c() +
  guides(colour = guide_legend("R ACF1     "))
```

## M3 feature space

```{r m3pca6, dependson="m3pca", fig.height=5}
p + geom_point(aes(color = lambda)) +
  coord_equal(ratio = 1) +
  scale_color_viridis_c() +
  guides(colour = guide_legend("Lambda    "))
```

## M3 feature space

```{r m3biplot, dependson="M3Features",fig.width=5.3,fig.height=5}
khs_pca %>%
  factoextra::fviz_pca_biplot(geom = "point", col.ind = "gray") +
  coord_equal(ratio = 1)
```

## What about the holes?

\placefig{0.4}{1.5}{height=8cm,width=12cm, trim=0 0 0 20, clip=true}{InstanceSpace}
\only<2->{\begin{textblock}{3}(1.3,1.8)\alert{What time series live here?}\end{textblock}}
\only<3->{\begin{textblock}{4}(8.5,7.8)\alert{Or here?}\end{textblock}}
\only<4>{\begin{textblock}{4}(8.9,1.8)\alert{Or here?}\end{textblock}}

## Generating new time series
\fontsize{13}{14.5}\sf

\begin{block}{}
We can use the feature space to:
\begin{itemize}
\item[\ding{229}] Generate new time series with similar features to existing series
\item[\ding{229}] Generate new time series where there are ``holes'' in the feature space.
\end{itemize}
\end{block}
\pause\vspace*{-0.4cm}

\begin{itemize}
\item Let $\{\text{PC}_1,\text{PC}_2,\dots,\text{PC}_{n}\}$ be a ``population'' of time series of specified length and period.
\item Genetic algorithm uses a process of selection, crossover and mutation to evolve the population towards a target point $T_i$.
\item Optimize: $\text{Fitness }(\text{PC}_j) = - \sqrt{(|\text{PC}_j-T_i|^2)}$.
\item Initial population random with some series in neighbourhood of $T_i$.
\end{itemize}

## Evolving new time series

\only<1>{\full{TargetedInstancesEgsLocations} }
\only<2>{\full{EvolvedInstancesEgs} }

## Evolving new time series
\only<1>{\full{UnknownEvolvedEgsLocations}}
\only<2>{\full{UnknownEvolvedEgs}}

## Evolving new time series

\only<1>{\placefig{2.1}{1.4}{height=7.6cm, width=8cm, trim=30 600 550 0, clip=TRUE}{EvolvedTSnbDiffLsep}}
\only<2>{\placefig{2.1}{1.4}{height=7.6cm, width=8cm, trim=606 600 0 0, clip=TRUE}{EvolvedTSnbDiffLsep}}
\only<3>{\placefig{2.1}{1.4}{height=7.52cm, width=8cm, trim=30 30 570 577, clip=TRUE}{EvolvedTSnbDiffLsep}}
\only<4>{\placefig{2.1}{1.4}{height=7.52cm, width=8cm, trim=606 30 0 577, clip=TRUE}{EvolvedTSnbDiffLsep}}
\begin{textblock}{3}(6,9)PC1\end{textblock}
\begin{textblock}{3}(1.3,4.55)PC2\end{textblock}

# R packages

```{r tourism, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, message = FALSE, warning = FALSE, cache = TRUE,
  dev.args = list(pointsize = 11)
)
  tourism <- tourism %>%
  mutate(
    State = recode(State,
                   "Australian Capital Territory" = "ACT",
                   "New South Wales"="NSW",
                   "Northern Territory" = "NT",
                   "Queensland" = "QLD",
                   "South Australia" = "SA",
                   "Tasmania" = "TAS",
                   "Victoria"="VIC",
                   "Western Australia" = "WA"
    )
  )
holidays <- tourism %>%
  filter(Purpose=="Visiting") %>%
  group_by(State) %>%
  summarise(
    Trips = sum(Trips)
  ) %>%
  select(Quarter, State, Trips)
```

## Tidyverts packages

\begin{textblock}{3.8}(8,0)\begin{alertblock}{}\Large\textbf{tidyverts.org}\end{alertblock}\end{textblock}

\placefig{1}{1.4}{width=4cm}{tsibble.png}
\placefig{5}{1.4}{width=4cm}{tsibbledata.png}
\placefig{3}{4.85}{width=4cm}{feasts.png}
\placefig{7}{4.85}{width=4cm}{fable.png}

## `tsibble` objects

\fontsize{10}{11.3}\sf

```{r, echo = TRUE}
library(tidyverse)
library(tsibble)
library(feasts)
tourism
```

\only<2->{\begin{textblock}{1.1}(2.1,5.07)
\begin{alertblock}{}\fontsize{10}{10}\sf Index\phantom{dg}\end{alertblock}
\end{textblock}}
\only<3->{\begin{textblock}{3.9}(3.65,5.07)
\begin{alertblock}{}\fontsize{10}{10}\sf Keys\phantom{dg}\end{alertblock}
\end{textblock}}
\only<4-5>{\begin{textblock}{1.5}(7.95,5.07)
\begin{alertblock}{}\fontsize{10}{10}\sf Measure\phantom{dg}\end{alertblock}
\end{textblock}}

\only<5>{\begin{textblock}{3}(9,6)
\begin{block}{}\fontsize{10}{10}\sf Domestic visitor nights in thousands by state/region and purpose.\phantom{dg}\end{block}
\end{textblock}}

## Feature extraction and statistics

\fontsize{9}{10}\sf

```{r features, echo=TRUE}
tourism %>% features(Trips, feature_set(tags="stl"))
```

## Feature extraction and statistics
\fontsize{8}{9}\sf

```{r features-plot, fig.height=4.6, echo=TRUE}
tourism %>% features(Trips, feature_set(tags="stl")) %>%
  ggplot(aes(x=trend_strength, y=seasonal_strength_year, col=Purpose)) +
    geom_point() + facet_wrap(vars(State))
```

\only<2->{\begin{textblock}{4.7}(7.8,7.3)
\begin{alertblock}{}\fontsize{10}{10}\sf
\begin{itemize}\tightlist
\item Holidays more seasonal than other travel.
\item WA has strongest trends.
\end{itemize}
\end{alertblock}\end{textblock}}

## Feature extraction and statistics
\fontsize{9}{9}\sf

Find the most seasonal time series:

```{r extreme, echo=TRUE}
most_seasonal <- tourism %>%
  features(Trips, feature_set(tags="stl")) %>%
  filter(seasonal_strength_year == max(seasonal_strength_year))
```

\pause\vspace*{-0.3cm}

```{r extreme2, fig.height=3., echo=TRUE}
tourism %>%
  right_join(most_seasonal, by = c("State","Region","Purpose")) %>%
  ggplot(aes(x = Quarter, y = Trips)) + geom_line() +
  facet_grid(vars(State,Region,Purpose))
```

```{r pca, echo=FALSE}
# Save pdf figures
savepdf <- function(file, width=16, height=10)
{
  fname <<- paste("figs/",file,".pdf",sep="")
  pdf(fname, width=width/2.54, height=height/2.54, pointsize=10)
  par(mgp=c(2.2,0.45,0), tcl=-0.4, mar=c(3.3,3.6,1.1,1.1))
}
endpdf <- function()
{
  crop::dev.off.crop(fname)
}
# Compute features
tourism_features <- tourism %>%
  features(Trips, feature_set(pkgs="feasts"))
# Compute PCs
pcs <- tourism_features %>% select(-State, -Region, -Purpose) %>%
  prcomp(scale=TRUE) %>% augment(tourism_features)
# Save some PC plots
savepdf("pca1", 18, 10)
pcs %>% ggplot(aes(x=.fittedPC1, y=.fittedPC2)) +
  geom_point() + theme(aspect.ratio=1)
endpdf()
savepdf("pca2", 18, 10)
pcs %>% ggplot(aes(x=.fittedPC1, y=.fittedPC2, col=State)) +
  geom_point() + theme(aspect.ratio=1)
endpdf()
savepdf("pca3", 18, 10)
pcs %>% ggplot(aes(x=.fittedPC1, y=.fittedPC2, col=Purpose)) +
  geom_point() + theme(aspect.ratio=1)
endpdf()
# Find outliers
outliers <- pcs %>%
  filter(.fittedPC1 == max(.fittedPC1) |
         (.fittedPC1 > 10 & .fittedPC2 > 2.5))
savepdf("pca4", 18, 10)
pcs %>% ggplot(aes(x=.fittedPC1, y=.fittedPC2, col=Purpose)) +
  geom_point() + theme(aspect.ratio=1) +
  geom_point(data=outliers, aes(x=.fittedPC1, y=.fittedPC2), col="black", shape=1, size=3)
endpdf()
```

## Feature extraction and statistics
\fontsize{9}{9}\sf

```{r tourismfeatures, echo=TRUE}
tourism_features <- tourism %>%
  features(Trips, feature_set(pkgs="feasts"))
```

```{r echo=FALSE}
tourism_features
```

\begin{textblock}{2.5}(9.6,1.3)
\begin{alertblock}{}\fontsize{10}{12}\sf
All features from the feasts package
\end{alertblock}
\end{textblock}

## Feature extraction and statistics
\fontsize{9}{9}\sf

```{r pcatable, echo=TRUE}
pcs <- tourism_features %>% select(-State, -Region, -Purpose) %>%
  prcomp(scale=TRUE) %>% augment(tourism_features)
```

```{r pcatable2, echo=FALSE, dependson='pcatable'}
pcs
```

\begin{textblock}{2.5}(9.6,3)
\begin{alertblock}{}\fontsize{10}{12}\sf
Principal components based on all features from the feasts package
\end{alertblock}
\end{textblock}

## Feature extraction and statistics
\fontsize{9}{9}\sf

\begin{textblock}{3.3}(.4,3)
\begin{alertblock}{}\fontsize{10}{12}\sf
Principal components based on all features from the feasts package
\end{alertblock}
\end{textblock}

```r
pcs %>% ggplot(aes(x=.fittedPC1, y=.fittedPC2)) +
  geom_point() + theme(aspect.ratio=1)
```

\placefig{4}{2.6}{height=6.4cm, width=12cm}{pca1}
\vspace*{10cm}

## Feature extraction and statistics
\fontsize{9}{9}\sf

\begin{textblock}{3.3}(.4,3)
\begin{alertblock}{}\fontsize{10}{12}\sf
Principal components based on all features from the feasts package
\end{alertblock}
\end{textblock}

```r
pcs %>% ggplot(aes(x=.fittedPC1, y=.fittedPC2, col=State)) +
  geom_point() + theme(aspect.ratio=1)
```

\placefig{4}{2.6}{height=6.4cm, width=12cm}{pca2}
\vspace*{10cm}

## Feature extraction and statistics
\fontsize{9}{9}\sf

\begin{textblock}{3.3}(.4,3)
\begin{alertblock}{}\fontsize{10}{12}\sf
Principal components based on all features from the feasts package
\end{alertblock}
\end{textblock}

```r
pcs %>% ggplot(aes(x=.fittedPC1, y=.fittedPC2, col=Purpose)) +
  geom_point() + theme(aspect.ratio=1)
```

\only<1>{\placefig{4}{2.6}{height=6.4cm, width=12cm}{pca3}}
\only<2>{\placefig{4}{2.6}{height=6.4cm, width=12cm}{pca4}}
\vspace*{10cm}

## Feature extraction and statistics
\fontsize{9}{9}\sf

```{r outliers2, fig.height=3.4, echo=TRUE}
pcs %>% filter(.fittedPC1 == max(.fittedPC1)) %>%
  left_join(tourism, by = c("State", "Region", "Purpose")) %>%
  ggplot(aes(x = Quarter, y = Trips)) +
    geom_line() +
    facet_grid(vars(State,Region,Purpose)) +
    ggtitle("Outlying time series in PC space") +
    theme(legend.position = "none")
```

## Feature extraction and statistics
\fontsize{9}{9}\sf

```{r outliers3, fig.height=3.4, echo=TRUE}
pcs %>% filter(.fittedPC1 > 10 & .fittedPC2 > 2.5) %>%
  left_join(tourism, by = c("State", "Region", "Purpose")) %>%
  ggplot(aes(x = Quarter, y = Trips)) +
    geom_line() +
    facet_grid(vars(State,Region,Purpose)) +
    ggtitle("Outlying time series in PC space") +
    theme(legend.position = "none")
```

# Feature-based anomaly detection

## Yahoo server metrics
\fontsize{13}{15}\sf\vspace*{-0.2cm}

  * Tens of thousands of time series collected at one-hour intervals over 1--2 months.
  * Consisting of several server metrics (e.g. CPU usage and paging views) from many server farms globally.
  * Aim: find unusual (anomalous) time series.

\placefig{0}{4.6}{width=13.7cm, trim=0 20 0 220, clip=TRUE}{serverfarm}
\vspace*{10cm}

## Yahoo server metrics
\vspace*{0.2cm}\par

```{r yahoodata, echo=FALSE}
yahoo <- tsfeatures::yahoo_data() %>%
  as_tsibble() %>%
  mutate(
    Time = hms::hms(
      day = trunc(index) - 1L,
      hour = as.integer((round(24 * (index - 1))) %% 24)
    )
  ) %>%
  as_tsibble(index = Time, key = key) %>%
  select(Time, key, value)
```

```{r yahoodataplot, echo=FALSE, dependson='yahoodata'}
random_yahoo <- function() {
  yahoo %>%
    filter(
      Time < hms::hms(day = 30, hour = 0),
      key %in% sample(unique(key), 1)
    ) %>%
    autoplot(value) +
    scale_x_time(
      breaks = 24 * 60 * 60 * seq(0, 50, by = 2),
      labels = seq(0, 50, by = 2)) +
    xlab("Day")
}
p1 <- random_yahoo()
p2 <- random_yahoo()
p3 <- random_yahoo()
p4 <- random_yahoo()

p1/p2/p3/p4
```

## Yahoo server metrics
\fontsize{11}{11.8}\sf\vspace*{-0.2cm}

* **ACF1**: first order autocorrelation = $\text{Corr}(Y_t,Y_{t-1})$
* Strength of **trend** and **seasonality** based on STL
* Size of seasonal **peak** and **trough**
* Spectral **entropy**
* **Lumpiness**: variance of block variances (block size 24).
* **Spikiness**: variances of leave-one-out variances of STL remainders.
* **Level shift**: Maximum difference in trimmed means of consecutive moving windows of size 24.
* **Variance change**: Max difference in variances of consecutive moving windows of size 24.
* **Flat spots**: Discretize sample space into 10 equal-sized intervals. Find max run length in any interval.
* Number of **crossing points** of mean line.
 * **Kullback-Leibler score**:
      Maximum of $D_{KL}(P\|Q) = \int P(x)\ln P(x)/ Q(x) dx$
       where $P$ and $Q$ are estimated by kernel density estimators applied to
       consecutive windows of size 48.
* **Change index**: Time of maximum KL score

## Feature space
\fontsize{11}{11}\sf

```{r yahoo, fig.height=4, fig.width=4, dependson='yahoodata'}
yahoo_features <- bind_cols(
  yahoo %>% features(value, features = list(
    mean = ~ mean(., na.rm = TRUE),
    var = ~ var(., na.rm = TRUE)
  )),
  yahoo %>% features(scale(value), features = list(
    ~ feat_acf(.),
    ~ feat_spectral(.),
    ~ n_flat_spots(.),
    ~ n_crossing_points(.),
    ~ var_tiled_var(., .period = 24, .size = 24),
    ~ shift_level_max(., .period = 24, .size = 24),
    ~ shift_var_max(., .period = 24, .size = 24),
    ~ shift_kl_max(., .period = 24, .size = 48),
    ~ feat_stl(., .period = 24, s.window = "periodic", robust = TRUE)
  ))
) %>%
  rename(lumpiness = var_tiled_var) %>%
  select(
    key, mean, var, acf1, trend_strength,
    seasonal_strength_24, linearity, curvature,
    seasonal_peak_24, seasonal_trough_24,
    spectral_entropy, lumpiness, spikiness,
    shift_level_max, shift_var_max,
    n_flat_spots, n_crossing_points,
    shift_kl_max, shift_kl_index
  )
```

```{r yahoo2, dependson='yahoo'}
hwl_pca <- yahoo_features %>%
  select(-key) %>%
  na.omit() %>%
  prcomp(scale = TRUE) %>%
  augment(na.omit(yahoo_features))
hwl_pca %>%
  as_tibble() %>%
  ggplot(aes(x = .fittedPC1, y = .fittedPC2)) +
  geom_point()
```

## Feature space

```{r yahoobiplot, dependson='yahoo'}
yahoo_features %>%
  select(-key) %>%
  na.omit() %>%
  prcomp(scale = TRUE) %>%
  factoextra::fviz_pca_biplot(geom = "point", col.ind = "gray")
```

\only<2>{\begin{textblock}{4.8}(7.6,5.3)\fontsize{11}{11}\sf
\begin{alertblock}{\fontsize{11}{11}\sffamily What is ``anomalous''?}
\begin{itemize}\tightlist
\item We need a measure of the ``anomalousness'' of a time series.
\item Rank points based on their local density using a bivariate kernel density estimate.
\end{itemize}
\end{alertblock}
\end{textblock}}

## Finding weird time series
\fontsize{10}{10}\sf

```{r hdryahoo, dependson="yahoo"}
hdrcde::hdrscatterplot(hwl_pca$.fittedPC1, hwl_pca$.fittedPC2, noutliers = 5) + xlab(".fittedPC1") + ylab(".fittedPC2")
```

\begin{textblock}{4.8}(7.7,6.9)\fontsize{10}{10}\sf
\begin{alertblock}{\fontsize{10}{10}\sffamily Highest Density Regions}
\begin{itemize}\tightlist
\item Estimate using \texttt{hdrcde} package
\item Highlight outlying points as those with lowest density.
\end{itemize}
\end{alertblock}
\end{textblock}

# Feature-based forecasting

## M competition: 1982

\placefig{0.1}{1.4}{height=8.2cm,width=10cm}{M1}


\begin{textblock}{5.5}(6.5,2)
  \begin{block}{M-competition}
  \begin{itemize}
  \item 1001 series from demography, industry, economics.
  \item Annual, quarterly, monthly data.
  \item Anyone could submit forecasts.
  \item Multiple forecast measures used.
  \end{itemize}
  \end{block}
\end{textblock}

## M3 competition: 2000

\full{M3paper}

## M4 competition: 2018

\full{m4}

## M4 competition: 2018

 * January -- May 2018
 * 100,000 time series: yearly, quarterly, monthly, weekly, daily, hourly.
 * Point forecast and prediction intervals assessed.
 * Code must be public
 * 248 registrations, 50 submissions.

\pause

### Winning methods
 1. Hybrid of Recurrent Neural Network and Exponential Smoothing models
 2. FFORMA: Feature-based forecast combinations using xgboost to find weights

## Features used to select a forecasting model

\begin{textblock}{12}(0.1,1.3)\small
\begin{multicols}{2}
  \begin{itemize}\tightlist
    \item length
    \item strength of seasonality
    \item strength of trend
    \item linearity
    \item curvature
    \item spikiness
    \item stability
    \item lumpiness
    \item parameter estimates of Holt's linear trend method
    \item spectral entropy
    \item Hurst exponent
    \item nonlinearity
    \item parameter estimates of Holt-Winters' additive method
    \item unit root test statistics
    \item crossing points, flat spots
    \item peaks, troughs
    \item ACF and PACF based features - calculated on raw, differenced, and remainder series.
    \item ARCH/GARCH statistics and ACF of squared series and residuals.
    \end{itemize}
\end{multicols}
\end{textblock}

## Features used to select a forecasting model

\alert{Why these features?}

 * Hyndman, Wang and Laptev. “Large scale unusual time series detection” (ICDM 2015).
 * Kang, Hyndman & Smith-Miles. “Visualising forecasting algorithm performance using time series instance spaces” (IJF 2017).
 * Talagala, Hyndman and Athanasopoulos. “Meta-learning how to forecast time series” (2018).
 * Implemented in the **feasts** R package

## \fontsize{16}{16}\bf\sffamily FFORMS: Feature-based FORecast Model Selection

\only<1>{\full{fw1}}
\only<2>{\full{fw2}}
\only<3>{\full{fw3}}
\only<4>{\full{fw4}}
\only<5>{\full{fw5}}
\only<6>{\full{fw6}}
\only<7>{\full{fw7}}
\only<8>{\full{fw8}}
\only<9>{\full{fw9}}
\only<10>{\full{fw10}}
\only<11>{\full{fw11}}
\only<12>{\full{fw12}}
\only<13>{\full{fw13}}
\only<14>{\full{fw14}}

\vspace*{10cm}

## Application to M competition data

\begin{block}{Experiment 1}
\centering\small\tabcolsep=0.1cm
\begin{tabular}{lrrrrr}
                 & Source & Y      & Q      & M \\
\midrule
Observed series  & M1     & 181    & 203    & 617 \\
Simulated series &        & 362000 & 406000 & 123400 \\
New series       & M3     & 645    & 756    & 1428
\end{tabular}
\end{block}
\begin{block}{Experiment 2}
\centering\small\tabcolsep=0.1cm
\begin{tabular}{lrrrrr}
                 & Source & Y       & Q       & M \\
\midrule
Observed series  & M3     & 645     & 756     & 1428 \\
Simulated series &        & 1290000 & 1512000 & 285600 \\
New series       & M1     & 181     & 203     & 617
\end{tabular}
\end{block}

## \fontsize{14}{14}\bf\sffamily Experiment 1: Distribution of time series in PCA space

\colorbox{black}{\color{white}{observed - M1}}

  \centerline{\includegraphics[width=\textwidth,height=7.5cm,keepaspectratio]{observed.pdf}}

## \fontsize{14}{14}\bf\sffamily Experiment 1: Distribution of time series in PCA space

\colorbox{black}{\color{white}{observed - M1}}\colorbox{ao(english)}{simulated}

  \centerline{\includegraphics[width=\textwidth,height=7.5cm,keepaspectratio]{simulated.pdf}}

## \fontsize{14}{14}\bf\sffamily Experiment 1: Distribution of time series in PCA space

\colorbox{black}{\color{white}{observed - M1}}\colorbox{ao(english)}{simulated}\colorbox{orange}{new - M3}
  \centerline{\includegraphics[width=\textwidth,height=7.5cm,keepaspectratio]{exp1pca-1.pdf}}


## \fontsize{14}{14}\bf\sffamily Experiment 2: Distribution of time series in PCA space

\colorbox{black}{\color{white}{observed - M3}} \colorbox{ao(english)}{simulated} \colorbox{aureolin}{subset} \colorbox{orange}{new - M1}
  \centerline{\includegraphics[width=\textwidth,height=7.5cm,keepaspectratio]{exp2pca-1.pdf}}

## Results: Yearly

```{r, message=FALSE, warning=FALSE, echo=FALSE}
method <- c(
  "RF-unbalanced", "RF-class priors", "auto.arima", "ets", "WN", "RW", "RWD", "Theta",
  "RF-unbalanced", "RF-class priors", "auto.arima", "ets", "WN", "RW", "RWD", "Theta"
)
Rank <- c(
  1.50, 1.50, 3.33, 5.00, 8.00, 7.00, 3.67, 6.00,
  3.50, 2.50, 5.83, 4.67, 9.00, 8.00, 1.00, 3.50
)
class <- c(0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1)
df <- data.frame(method = method, Rank = Rank, class = class)
ggplot(data = df, aes(x = method, y = Rank, fill = factor(class))) +
  geom_bar(position = "dodge", stat = "identity") +
  coord_flip() +
  scale_x_discrete(
    limits = c("WN", "RW", "auto.arima", "ets", "Theta", "RWD", "RF-class priors", "RF-unbalanced"),
    labels = c("WN", "RW", "auto.arima", "ets", "Theta", "RWD", "RF-class priors", "RF-unbalanced")
  ) + scale_fill_brewer(
    breaks = c(1, 0),
    labels = c("Experiment 1 (new: M3)", "Experiment 2 (new: M1)"),
    palette = "Set1"
  ) +
  theme(
    axis.title.y = element_blank(), legend.title = element_blank(),
    text = element_text(size = 20)
  )
```

## Results: Quarterly

```{r, message=FALSE, warning=FALSE, echo=FALSE}
library(ggplot2)
method <- c(
  "RF-unbalanced", "RF-class priors", "auto.arima", "ets", "WN", "RW", "RWD", "STL-AR", "Theta", "Snaive",
  "RF-unbalanced", "RF-class priors", "auto.arima", "ets", "WN", "RW", "RWD", "STL-AR", "Theta", "Snaive"
)
Rank <- c(
  1.00, 2.63, 5.25, 3.00, 10.00, 7.50, 5.38, 8.63, 3.88, 7.75, 2.25,
  3.13, 4.75, 3.75, 10.00, 7.00, 6.50, 8.34, 2.50, 6.75
)
class <- c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)
df <- data.frame(method = method, Rank = Rank, class = class)
ggplot(data = df, aes(x = method, y = Rank, fill = factor(class))) +
  geom_bar(position = "dodge", stat = "identity") +
  coord_flip() +
  scale_x_discrete(
    limits = c("WN", "RW", "RWD", "STL-AR", "Snaive", "auto.arima", "ets", "Theta", "RF-class priors", "RF-unbalanced"),
    labels = c("WN", "RW", "RWD", "STL-AR", "Snaive", "auto.arima", "ets", "Theta", "RF-class priors", "RF-unbalanced")
  ) + scale_fill_brewer(
    breaks = c(1, 0),
    labels = c("Experiment 1 (new: M3)", "Experiment 2 (new: M1)"),
    palette = "Set1"
  ) +
  theme(
    axis.title.y = element_blank(), legend.title = element_blank(),
    text = element_text(size = 20)
  )
```

## Results: Monthly

```{r, message=FALSE, warning=FALSE, echo=FALSE}
library(ggplot2)
method <- c(
  "RF-unbalanced", "RF-class priors", "auto.arima", "ets", "WN", "RW", "RWD", "STL-AR", "Theta", "Snaive",
  "RF-unbalanced", "RF-class priors", "auto.arima", "ets", "WN", "RW", "RWD", "STL-AR", "Theta", "Snaive"
)
Rank <- c(1.77, 2.83, 4.94, 3.44, 10.00, 7.25, 8.61, 7.38, 2.27, 6.47, 3.22, 2.00, 2.83, 2.72, 10.00, 8.03, 6.89, 7.89, 4.22, 7.19)
class <- c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)
df <- data.frame(method = method, Rank = Rank, class = class)
ggplot(data = df, aes(x = method, y = Rank, fill = factor(class))) +
  geom_bar(position = "dodge", stat = "identity") +
  coord_flip() +
  scale_x_discrete(
    limits = c("WN", "RW", "RWD", "STL-AR", "Snaive", "auto.arima", "ets", "Theta", "RF-class priors", "RF-unbalanced"),
    labels = c("WN", "RW", "RWD", "STL-AR", "Snaive", "auto.arima", "ets", "Theta", "RF-class priors", "RF-unbalanced")
  ) + scale_fill_brewer(
    breaks = c(1, 0),
    labels = c("Experiment 1 (new: M3)", "Experiment 2 (new: M1)"),
    palette = "Set1"
  ) +
  theme(
    axis.title.y = element_blank(), legend.title = element_blank(),
    text = element_text(size = 20)
  )
```

## \fontsize{15}{15}\bf\sffamily FFORMA: Feature-based FORecast Model Averaging

 * Like FFORMS but using gradient boosted trees (xgboost) rather than random forest.
 * Trained on temporal holdout version of M4 dataset, where size of test sets equal to required forecast horizons
 * Optimization criterion: forecast accuracy not classification accuracy.
 * Probability of each model being best is used to construct model weights for combination forecast.
 * 5 days computing time.

## \fontsize{15}{15}\sffamily\bfseries FFORMA: Feature-based FORecast Model Averaging

### Models included

1. Naive
1. Seasonal naive
1. Random walk with drift
1. Theta method
1. ARIMA
1. ETS
1. TBATS
1. STL decomposition with AR for seasonally adjusted series
1. Neural network autoregression

## \fontsize{15}{15}\bf\sffamily FFORMA: Feature-based FORecast Model Averaging

\placefig{0.2}{1.4}{width=12.4cm, trim=0 0 0 70, clip=true}{fforma_graphic}


\vspace*{5.2cm}

### M4 competition results (based on average OWA)

```{r, results='asis'}
tribble(
    ~Place, ~OWA, ~Method,
    "1st", 0.821, NA,
    "2nd", 0.838, "(FFORMA)",
    "3rd", 0.841, NA
  ) %>%
  baretable(digits=3)
```


## \fontsize{15}{15}\bf\sffamily FFORMA: Feature-based FORecast Model Averaging

\only<1>{\placefig{0.2}{1.4}{width=12.4cm, trim=0 0 0 0, clip=true}{prototypes}}
\only<2>{\placefig{0.2}{1.4}{width=12.4cm, trim=0 0 0 0, clip=true}{prototype1}}
\only<3>{\placefig{0.2}{1.4}{width=12.4cm, trim=0 0 0 0, clip=true}{prototype2}}
\only<4>{\placefig{0.2}{1.4}{width=12.4cm, trim=0 0 0 0, clip=true}{prototype3}}
\only<5>{\placefig{0.2}{1.4}{width=12.4cm, trim=0 0 0 0, clip=true}{prototype4}}
\only<6>{\placefig{0.2}{1.4}{width=12.4cm, trim=0 0 0 0, clip=true}{prototype5}}

## Acknowledgments

\begin{textblock}{12.5}(0.2,1.2)
\begin{block}{}\fontsize{9}{10}\sf
\centering\begin{tabular}{p{2.6cm}p{2.3cm}p{2.9cm}l}
\includegraphics[height=2cm, width=10cm, keepaspectratio]{dilini} &
\includegraphics[height=2cm, width=10cm, keepaspectratio]{earowang}&
\includegraphics[height=2cm, width=10cm, keepaspectratio]{kate} &
\includegraphics[height=2cm, width=10cm, keepaspectratio]{george}\\
Dilini Talagala  & Earo Wang & Kate Smith-Miles & George Athanasopoulos \\
\includegraphics[height=2cm, width=10cm, keepaspectratio]{thiyanga} &
\includegraphics[height=2cm, width=10cm, keepaspectratio]{yanfei} &
\includegraphics[height=2cm, width=10cm, keepaspectratio]{mitch} &
\includegraphics[height=2cm, width=10cm, keepaspectratio]{pablo} \\
Thiyanga Talagala & Yanfei Kang & Mitchell O'Hara-Wild & Pablo Montero-Manso
 \end{tabular}
\end{block}
\end{textblock}

\begin{textblock}{10}(1.6,7.8)
\begin{alertblock}{Papers}
Available from \url{robjhyndman.com}
\end{alertblock}
\end{textblock}
