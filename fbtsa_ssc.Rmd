---
title: "Feature-based time series analysis"
date: "2/3 February 2022"
author: "Rob J Hyndman"
fontsize: 14pt
classoption: aspectratio=169
toc: true
titlefontsize: 28pt
output:
  binb::monash:
    colortheme: monashwhite
    highlight: pygments
    fig_width: 8
    fig_height: 3.3
    keep_tex: yes
    includes:
      in_header: preamble2022.tex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE,
  cache = TRUE
)
library(fpp3)
library(patchwork)
library(glue)
library(GGally)
savepdf <- function(file, width = 16, height = 10) {
  fname <<- paste("figs/", file, ".pdf", sep = "")
  pdf(fname, width = width / 2.54, height = height / 2.54, pointsize = 10, bg = "white")
  par(mgp = c(2.2, 0.45, 0), tcl = -0.4, mar = c(3.3, 3.6, 1.1, 1.1))
}
endpdf <- function() {
  dev.off()#crop::dev.off.crop(fname)
}
gghist <- function(data, mapping, ...) {
  x <- GGally::eval_data_col(data, mapping$x)
  bw <- 0.2 * bw.nrd0(x) + 0.8 * bw.SJ(x)
  p <- ggplot(data, mapping) +
    geom_density(col = NA, fill = "#cc5900", bw = bw)
  return(p)
}
# Function to produce very basic table, no lines or headings
baretable <- function(tbl, digits = 0,
                      include.colnames=FALSE, include.rownames=FALSE,
                      hline.after=NULL,
                      size = getOption("xtable.size", NULL),
                      add.to.row =  getOption("xtable.add.to.row", NULL),
                      ...) {
  tbl %>%
    xtable::xtable(digits = digits, ...) %>%
    print(
      include.colnames = include.colnames,
      include.rownames = include.rownames,
      hline.after = hline.after,
      comment = FALSE,
      latex.environments = NULL,
      floating = FALSE,
      size=size,
      add.to.row=add.to.row,
      sanitize.text.function = function(x) {
        x
      }
    )
}
set.seed(20190927)
options(digits = 3, width = 63)

# Colors to be viridis for continuous scales and Okabe for discrete scales
options(
  digits = 3,
  width = 90,
  ggplot2.continuous.color = "viridis",
  ggplot2.continuous.fill = "viridis",
  ggplot2.discrete.colour = c("#D55E00", "#0072B2", "#009E73", "#CC79A7", "#E69F00", "#56B4E9", "#F0E442"),
  ggplot2.discrete.fill = c("#D55E00", "#0072B2", "#009E73", "#CC79A7", "#E69F00", "#56B4E9", "#F0E442")
)

# Neater data sets
tourism <- tsibble::tourism %>%
  mutate(
    State = recode(State,
      "Australian Capital Territory" = "ACT",
      "New South Wales" = "NSW",
      "Northern Territory" = "NT",
      "Queensland" = "QLD",
      "South Australia" = "SA",
      "Tasmania" = "TAS",
      "Victoria" = "VIC",
      "Western Australia" = "WA"
    ),
    Region = stringr::str_remove(Region, "Australia's ")
  )
```

# Feature-based visualization

## M3 competition: 2000
\full{M3paper}
\only<2>{
\placefig{2}{5}{height=3cm, width=10cm, keepaspectratio=true}{SMakridakis}
\placefig{11}{5}{height=3cm, width=10cm, keepaspectratio=true}{MHibon}}


## M3 competition: 2000
\fontsize{13}{14}\sf
\begin{block}{}
``The M3-Competition is a final attempt by the authors to settle the accuracy issue of
various time series methods\dots\ The extension involves the inclusion of more methods/ researchers (in particular in the areas of neural networks and expert systems) and more series.''
\end{block}

  * 3003 series
  * All data from business, demography, finance and economics.
  * Series length between 14 and 126.
  * Either non-seasonal, monthly or quarterly.
  * All time series positive.

## How to plot lots of time series?

```{r m3data, message=FALSE}
m3_yearly <- monash_forecasting_repository(4656222) %>%
  mutate(
    year = year(start_timestamp),
    series_name = stringr::str_replace(series_name, "T", "Y")
  ) %>%
  as_tsibble(index=year) %>%
  select(-start_timestamp)
m3_quarterly <- monash_forecasting_repository(4656262) %>%
  mutate(
    quarter = yearquarter(start_timestamp),
    series_name = stringr::str_replace(series_name, "T", "Q")
  ) %>%
  as_tsibble(index=quarter) %>%
  select(-start_timestamp)
m3_monthly <- monash_forecasting_repository(4656298) %>%
  mutate(
    month = yearmonth(start_timestamp),
    series_name = stringr::str_replace(series_name, "T", "M")
  ) %>%
  as_tsibble(index=month) %>%
  select(-start_timestamp)
m3_other <- monash_forecasting_repository(4656335) %>%
  mutate(series_name = stringr::str_replace(series_name, "T","O"))
# Fix error in series M1385
m3_monthly <- m3_monthly %>% mutate(value = abs(value))
```

```{r scalem3}
scalem3 <- list()
for (i in seq(3003)) {
  scalem3[[i]] <- Mcomp::M3[[i]]$x - min(Mcomp::M3[[i]]$x)
  scalem3[[i]] <- as.numeric(scalem3[[i]] / max(scalem3[[i]]))
}
k <- sample(1:3003, 3003)
files <- c(1:5, seq(10, 50, by = 10), 100, 200, 500, 3003)
cols <- sample(rainbow(3003))
for (i in files) {
  fname <- paste("M3data", i, sep = "")
  savepdf(fname)
  plot(0, 0, ylim = range(scalem3), xlim = c(0, 1), xlab = "Time", ylab = "", type = "n")
  for (i in 1:i) {
    lines((1:length(scalem3[[k[i]]])) / length(scalem3[[k[i]]]), scalem3[[k[i]]],
      col = cols[i]
    )
  }
  endpdf()
}
```

\only<1>{\full{M3data1}}
\only<2>{\full{M3data2}}
\only<3>{\full{M3data3}}
\only<4>{\full{M3data4}}
\only<5>{\full{M3data5}}
\only<6>{\full{M3data10}}
\only<7>{\full{M3data20}}
\only<8>{\full{M3data30}}
\only<9>{\full{M3data40}}
\only<10>{\full{M3data50}}
\only<11>{\full{M3data100}}
\only<12>{\full{M3data200}}
\only<13>{\full{M3data500}}
\only<14>{\full{M3data3003}}

## Key idea
\fontsize{13}{14}\sf
\placefig{11.1}{.5}{width=4.3cm}{tukey}
\begin{textblock}{3}(12.7,6.4)\small\textit{John W Tukey}\end{textblock}
\begin{textblock}{8}(0.7,1.2)
\begin{alertblock}{Cognostics}
Computer-produced diagnostics\\ (Tukey and Tukey, 1985).
\end{alertblock}
\end{textblock}\pause
\vspace*{2.1cm}

\alert{Examples for time series}

  * lag correlation
  * size and direction of trend
  * strength of seasonality
  * timing of peak seasonality
  * spectral entropy

\vspace*{0.1cm}
\begin{block}{}
Called ``features'' in the machine learning literature\\ and ``statistics'' in the statistics literature.
\end{block}

## An STL decomposition: M695

\begin{textblock}{5}(9,0.2)
\begin{alertblock}{STL decomposition}
\centerline{$Y_t = S_t + T_t + R_t$}
\end{alertblock}
\end{textblock}
\begin{textblock}{1}(8.6,2.6)
$y_t$\\[.7cm]
$T_t$\\[.7cm]
$S_t$\\[.7cm]
$R_t$
\end{textblock}

```{r stl, fig.height=6, fig.width=7}
m3_monthly %>%
  filter(series_name == "M695") %>%
  model(stl = STL(value)) %>%
  components() %>%
  autoplot() + ylab("") + xlab("") +
  scale_x_yearmonth(
    breaks = seq(as_date("1982-01-01"), as_date("1993-01-01"), by = "year"),
    labels = 1982:1993, minor_breaks = NULL
  )
```

\begin{textblock}{6}(9.5,2.6)
\only<2->{\begin{block}{Trend strength}
$$\max\left(0, 1-\frac{\text{Var}(R_t)}{\text{Var}(T_t+R_t)}\right)$$
\end{block}}
\only<3>{\begin{block}{Seasonal strength}
$$\max\left(0, 1-\frac{\text{Var}(R_t)}{\text{Var}(S_t+R_t)}\right)$$
\end{block}}
\end{textblock}

## Candidate features
\fontsize{13}{14.5}\sf

\begin{block}{}
For series with different lengths, scales, domains, etc., we need features that are:
\vspace*{-0.4cm}\begin{multicols}{2}
\begin{itemize}\tightlist
\item scale-independent
\item ergodic
\end{itemize}
\end{multicols}
\end{block}\pause

1. Seasonal period
2. Strength of seasonality: $\max\left(0,1 - \frac{\Var(R_t)}{\Var(Y_t-T_t)}\right)$
3. Strength of trend:  $\max\left(0,1 - \frac{\Var(R_t)}{\Var(Y_t-S_t)}\right)$
4. Lag-1 autocorrelation of STL remainder series: Corr$(R_t,R_{t-1})$
4. Spectral entropy: $H = - \int_{-\pi}^{\pi} f_y(\lambda) \log f_y(\lambda) d\lambda$, where $f_y(\lambda)$ is spectral density of $Y_t$. Low values of $H$ suggest a time series that is easier to forecast (more signal).
5. Optimal Box-Cox transformation of data


```{r m3_features}
# Use tsfeatures for consistency with KHS paper
khs_stl <- function(x, period=1) {
  x <- ts(x, frequency=period)
  output <- c(n = length(x), frequency = period, tsfeatures::entropy(x))
  lambda <- forecast::BoxCox.lambda(ts(x, frequency = period),
    lower = 0, upper = 1, method = "loglik"
  )
  stlfeatures <- tsfeatures::stl_features(box_cox(x, lambda), s.window="periodic", robust=TRUE)
  if(period == 1L) {
    stlfeatures <- c(stlfeatures[c("trend","e_acf1")], seasonal_strength=0)
  }
  else {
    stlfeatures <- stlfeatures[c("trend","e_acf1", "seasonal_strength")]
  }
  c(output, stlfeatures, lambda = lambda)
}
m3_features <- bind_rows(
    m3_yearly %>% features(value, features = khs_stl, period = 1),
    m3_quarterly %>% features(value, features = khs_stl, period = 4),
    m3_monthly %>% features(value, features = khs_stl, period = 12),
    m3_other %>% features(value, features = khs_stl, period = 1)
  )
```

```{r M3examples, include=FALSE, dependson="M3Features"}
m3plot <- function(sn) {
  sn <- sn[1]
  if(substr(sn,1,1) == "Y")
    use <- m3_yearly 
  else if(substr(sn, 1, 1) == "Q") 
    use <- m3_quarterly
  else if(substr(sn, 1, 1) == "M") 
    use <- m3_monthly
  else if(substr(sn, 1, 1) == "O") 
    use <- m3_other
  else
    stop("Unknown series")
  use %>% 
    filter(series_name == sn) %>% 
    autoplot(value) + ylab(sn) + xlab("")
}
# Consider only long series for plotting
m3_long <- m3_features %>% filter(n > 50)
fnames <- m3_long %>%
  select(-n, -series_name) %>%
  colnames()
for (i in seq_along(fnames)) {
  savepdf(paste(fnames[i], "Lo", sep = ""), width = 20, height = 7)
  m3_long %>%
    filter(m3_long[, fnames[i]] == min(m3_long[, fnames[i]])) %>%
    pull(series_name) %>%
    m3plot() %>%
    print()
  endpdf()
  savepdf(paste(fnames[i], "Hi", sep = ""), width = 20, height = 7)
  m3_long %>%
    filter(m3_long[, fnames[i]] == max(m3_long[, fnames[i]])) %>%
    pull(series_name) %>%
    m3plot() %>%
    print()
  endpdf()
}
```

## Distribution of Period for M3

```{r M3period, dependson="M3Features"}
m3_features %>%
  GGally::ggally_barDiag(
    mapping = aes(frequency),
    binwidth = 0.2, colour = "#cc5900", fill = "#cc5900"
  ) +
  scale_x_continuous(breaks = seq(12), minor_breaks = NULL)
```

## Distribution of Seasonality for M3

```{r M3season, dependson="M3Features"}
m3_features %>% gghist(aes(x = seasonal_strength))
```

\only<2->{
\begin{textblock}{6}(0.4,3)
  \begin{alertblock}{Low Seasonality}
    \includegraphics[width=6cm]{seasonal_strengthLo.pdf}
  \end{alertblock}
\end{textblock}
}
\only<3>{
\begin{textblock}{6}(9.6,3)
  \begin{alertblock}{High Seasonality}
    \includegraphics[width=6cm]{seasonal_strengthHi.pdf}
  \end{alertblock}
\end{textblock}
}

## Distribution of Trend for M3

```{r M3trend, dependson="M3Features"}
m3_features %>% gghist(aes(x = trend))
```

\only<2->{
\begin{textblock}{6}(0.4,3)
  \begin{alertblock}{Low Trend}
    \includegraphics[width=6cm]{trendLo.pdf}
  \end{alertblock}
\end{textblock}
}
\only<3>{
\begin{textblock}{6}(9.6,3)
  \begin{alertblock}{High Trend}
    \includegraphics[width=6cm]{trendHi.pdf}
  \end{alertblock}
\end{textblock}
}

## Distribution of Residual ACF1 for M3

```{r M3ACF1, dependson="M3Features"}
m3_features %>% gghist(aes(x = e_acf1))
```

\only<2->{
\begin{textblock}{6}(0.4,3)
  \begin{alertblock}{Low ACF1}
    \includegraphics[width=6cm]{e_acf1Lo.pdf}
  \end{alertblock}
\end{textblock}
}
\only<3>{
\begin{textblock}{6}(9.6,3)
  \begin{alertblock}{High ACF1}
    \includegraphics[width=6cm]{e_acf1Hi.pdf}
  \end{alertblock}
\end{textblock}
}

## Distribution of Spectral Entropy for M3

```{r M3entropy, dependson="M3Features"}
m3_features %>% gghist(aes(x = entropy))
```

\only<2->{
\begin{textblock}{6}(0.4,3)
  \begin{alertblock}{Low Entropy}
    \includegraphics[width=6cm]{entropyLo.pdf}
  \end{alertblock}
\end{textblock}
}
\only<3>{
\begin{textblock}{6}(9.6,3)
  \begin{alertblock}{High Entropy}
    \includegraphics[width=6cm]{entropyHi.pdf}
  \end{alertblock}
\end{textblock}
}

## Feature distributions

```{r ACF1SE, dependson="M3Features"}
m3_features %>%
  ggplot(aes(x = entropy, y = e_acf1)) +
  geom_point()
```

## Feature distributions

```{r TrendSE, dependson="M3Features"}
m3_features %>%
  ggplot(aes(x = entropy, y = trend)) +
  geom_point()
```

## Feature distributions

```{r M3pairs, include=FALSE, dependson="M3Features"}
# Fig 1 of paper
yk_ggally_densityDiag <- wrap(gghist, adjust = 0.5)
yk_ggally_barDiag <- wrap(ggally_barDiag,
  colour = "#cc5900",
  fill = "#cc5900", width = 0.2
)
m3_features %>%
  mutate(period = as.character(frequency)) %>%
  select(period, entropy, trend, seasonal_strength, e_acf1, lambda) %>%
  GGally::ggpairs(
    diag = list(
      continuous = yk_ggally_densityDiag,
      discrete = yk_ggally_barDiag
    ),
    axisLabels = "none",
    lower = list(continuous = wrap("points", alpha = 0.5, size = 0.2))
  ) -> p
#print(p)
savepdf("PairwisePlot", width=18, height=18)
print(p)
endpdf()
```

\centerline{\includegraphics[width=7.5cm, height=20cm]{PairwisePlot}}

## Dimension reduction for time series

```{r m3sample, include=FALSE, dependson='scalem3'}
j <- sample(1:3003, 100)
ncol <- 5
n <- length(j)
savepdf("M3sample")
plot(0, 0, ylim = c(0, n / ncol), xlim = c(0, ncol * 1.2), yaxt = "n", xaxt = "n", ylab = "", xlab = "", bty = "n", type = "n")
for (i in 1:n) {
  lines(
    (1:length(scalem3[[j[i]]])) / length(scalem3[[j[i]]]) + ((i - 1) %% ncol) * 1.1,
    scalem3[[j[i]]] + trunc((i - 1) / ncol)
  )
}
endpdf()
```

```{r m3pca}
# 2-d Feature space (Top of Fig 2)
khs_pca <- m3_features %>%
  select(-series_name, -n) %>%
  prcomp(scale = TRUE)
#khs_pca$x[, 2] <- -khs_pca$x[, 2]
khs_pca$rotation[, 2] <- -khs_pca$rotation[, 2]
p <- khs_pca %>%
  broom::augment(m3_features) %>%
  ggplot(aes(x = .fittedPC1, y = .fittedPC2)) +
  geom_point()  +
  coord_equal(ratio = 1)
p1 <- p + geom_point(aes(color = factor(frequency))) + 
  scale_color_viridis_d() + guides(colour = guide_legend("Frequency"))
p2 <- p + geom_point(aes(color = seasonal_strength)) +
  scale_color_viridis_c() + guides(colour = guide_legend("Seasonality"))
p3 <- p + geom_point(aes(color = trend)) +
  scale_color_viridis_c() + guides(colour = guide_legend("Trend"))
p4 <- p + geom_point(aes(color = entropy)) +
  scale_color_viridis_c() + guides(colour = guide_legend("Entropy"))
p5 <- p + geom_point(aes(color = e_acf1)) +
  scale_color_viridis_c() + guides(colour = guide_legend("R ACF1"))
p6 <- p + geom_point(aes(color = lambda)) +
  scale_color_viridis_c() + guides(colour = guide_legend("Lambda"))
palign <- patchwork::align_patches(p1, p2, p3, p4, p5, p6, p)

savepdf("FeatureSpace", height = 13, width = 13)
print(palign[[7]])
endpdf()
for(i in seq(6)) {
  savepdf(paste0("m3pca",i), height = 13, width = 13)
  print(palign[[i]])
  endpdf()
}
```

\only<1->{\placefig{0}{1.5}{width=5cm,height=8.3cm,trim=50 50 200 50,clip=TRUE}{M3sample}}
\only<2->{\placefig{8}{1.3}{width=6cm}{PairwisePlot}}
\only<3>{\placefig{6.2}{5.3}{width=5cm, clip=true, trim=0 50 90 50}{FeatureSpace}}

\only<2->{\placefig{5.5}{2}{width=2cm}{arrow}}
\only<3>{\placefig{9.4}{4.8}{width=2cm,angle=-90}{arrow}}

\only<2->{\begin{textblock}{2.1}(5.5,2.6)
\begin{alertblock}{}\small
Feature calculation
\end{alertblock}
\end{textblock}}

\only<3->{\begin{textblock}{2.8}(10.7,5.1)
\begin{alertblock}{}\small
Principal component decomposition
\end{alertblock}
\end{textblock}}

## M3 feature space

\placefig{.5}{1.4}{height=7.8cm, width=20cm, clip=true, trim=0 50 0 50}{FeatureSpace}

\begin{textblock}{4}(8.3,.5)
\begin{block}{}\fontsize{12}{13}\sf
First two PCs explain `r sprintf("%3.1f",100*sum(khs_pca$sdev[1:2]^2)/sum(khs_pca$sdev^2))`\% of the variance.
\end{block}
\end{textblock}

## M3 feature space

\only<1>{\placefig{.5}{1.4}{height=7.8cm, width=20cm, clip=true, trim=0 50 0 50}{m3pca1}}
\only<2>{\placefig{.5}{1.4}{height=7.8cm, width=20cm, clip=true, trim=0 50 0 50}{m3pca2}}
\only<3>{\placefig{.5}{1.4}{height=7.8cm, width=20cm, clip=true, trim=0 50 0 50}{m3pca3}}
\only<4>{\placefig{.5}{1.4}{height=7.8cm, width=20cm, clip=true, trim=0 50 0 50}{m3pca4}}
\only<5>{\placefig{.5}{1.4}{height=7.8cm, width=20cm, clip=true, trim=0 50 0 50}{m3pca5}}
\only<6>{\placefig{.5}{1.4}{height=7.8cm, width=20cm, clip=true, trim=0 50 0 50}{m3pca6}}

## M3 feature space

```{r m3biplot, dependson="M3Features",fig.width=5.3,fig.height=5}
khs_pca %>%
  factoextra::fviz_pca_biplot(geom = "point", col.ind = "gray") +
  coord_equal(ratio = 1)
```

## What about the holes?

\placefig{0.4}{1.5}{height=8cm,width=12cm, trim=0 0 0 20, clip=true}{InstanceSpace}
\only<2->{\begin{textblock}{3}(1.3,1.8)\alert{What time series live here?}\end{textblock}}
\only<3->{\begin{textblock}{4}(8.5,7.8)\alert{Or here?}\end{textblock}}
\only<4>{\begin{textblock}{4}(8.9,1.8)\alert{Or here?}\end{textblock}}

## Generating new time series
\fontsize{13}{14.5}\sf

\begin{block}{}
We can use the feature space to:
\begin{itemize}
\item[\ding{229}] Generate new time series with similar features to existing series
\item[\ding{229}] Generate new time series where there are ``holes'' in the feature space.
\end{itemize}
\end{block}
\pause\vspace*{-0.4cm}

\begin{itemize}
\item Let $\{\text{PC}_1,\text{PC}_2,\dots,\text{PC}_{n}\}$ be a ``population'' of time series of specified length and period.
\item Genetic algorithm uses a process of selection, crossover and mutation to evolve the population towards a target point $T_i$.
\item Optimize: $\text{Fitness }(\text{PC}_j) = - \sqrt{(|\text{PC}_j-T_i|^2)}$.
\item Initial population random with some series in neighbourhood of $T_i$.
\end{itemize}

## Evolving new time series

\placefig{0.}{1.45}{width=7.6cm,height=20cm}{TargetedInstancesEgsLocations} 
\only<2>{\placefig{8.3}{1.4}{width=7.6cm,height=20cm}{EvolvedInstancesEgs}}

## Evolving new time series
\placefig{0.}{1.45}{width=7.6cm,height=20cm}{UnknownEvolvedEgsLocations}
\only<2>{\placefig{8.3}{1.4}{width=7.6cm,height=20cm}{UnknownEvolvedEgs}}

## Evolving new time series

\only<1>{\placefig{2.1}{1.4}{height=7.6cm, width=8cm, trim=30 600 550 0, clip=TRUE}{EvolvedTSnbDiffLsep}}
\only<2>{\placefig{2.1}{1.4}{height=7.6cm, width=8cm, trim=606 600 0 0, clip=TRUE}{EvolvedTSnbDiffLsep}}
\only<3>{\placefig{2.1}{1.4}{height=7.52cm, width=8cm, trim=30 30 570 577, clip=TRUE}{EvolvedTSnbDiffLsep}}
\only<4>{\placefig{2.1}{1.4}{height=7.52cm, width=8cm, trim=606 30 0 577, clip=TRUE}{EvolvedTSnbDiffLsep}}
\begin{textblock}{3}(6,9)PC1\end{textblock}
\begin{textblock}{3}(1.3,4.55)PC2\end{textblock}

# Australian tourism activity

```{r tourism, include=FALSE}
holidays <- tourism %>%
  filter(Purpose=="Visiting") %>%
  group_by(State) %>%
  summarise(
    Trips = sum(Trips)
  ) %>%
  select(Quarter, State, Trips)
```

## Tidyverts packages

\begin{textblock}{3.8}(8,0)\begin{alertblock}{}\Large\textbf{tidyverts.org}\end{alertblock}\end{textblock}

\placefig{1}{1.4}{width=3.7cm}{tsibble.png}
\placefig{5}{1.4}{width=3.7cm}{tsibbledata.png}
\placefig{3}{4.75}{width=3.7cm}{feasts.png}
\placefig{7}{4.75}{width=3.7cm}{fable.png}

## `tsibble` objects

\fontsize{10}{11.3}\sf

```{r, echo = TRUE}
library(tidyverse)
library(tsibble)
library(feasts)
tourism
```

\only<2->{\begin{textblock}{1.1}(2.1,5.07)
\begin{alertblock}{}\fontsize{10}{10}\sf Index\phantom{dg}\end{alertblock}
\end{textblock}}
\only<3->{\begin{textblock}{3.9}(3.65,5.07)
\begin{alertblock}{}\fontsize{10}{10}\sf Keys\phantom{dg}\end{alertblock}
\end{textblock}}
\only<4-5>{\begin{textblock}{1.5}(7.95,5.07)
\begin{alertblock}{}\fontsize{10}{10}\sf Measure\phantom{dg}\end{alertblock}
\end{textblock}}

\only<5>{\begin{textblock}{3}(9,6)
\begin{block}{}\fontsize{10}{10}\sf Domestic visitor nights in thousands by state/region and purpose.\phantom{dg}\end{block}
\end{textblock}}


## STL-based features
\fontsize{9}{9}\sf

```{r features, echo=TRUE}
tourism %>%
  features(Trips, feature_set(tags="stl"))
```

## STL-based features
\fontsize{9}{9}\sf

```{r features-plot, fig.height=4, fig.width=6, out.height="67%", echo=TRUE}
tourism %>%
  features(Trips, feat_stl) %>%
  ggplot(aes(x = trend_strength, y = seasonal_strength_year, col = Purpose)) +
  geom_point() + facet_wrap(vars(State))
```

\only<2->{\begin{textblock}{5.3}(9.8,6.6)
\begin{alertblock}{}\fontsize{12}{12}\sf
\begin{itemize}\tightlist
\item Holidays more seasonal than other travel.
\item WA has strongest trends.
\end{itemize}
\end{alertblock}\end{textblock}}

## STL-based features

Find the most seasonal time series:

\fontsize{9}{9}\sf

```{r extreme, fig.height=2, echo=TRUE}
tourism %>%
  features(Trips, feat_stl) %>%
  filter(seasonal_strength_year == max(seasonal_strength_year)) %>%
  left_join(tourism, by = c("State", "Region", "Purpose")) %>%
  ggplot(aes(x = Quarter, y = Trips)) +
  geom_line() +
  facet_grid(vars(State, Region, Purpose))
```

```{r pca, echo=FALSE}
# Save pdf figures
savepdf <- function(file, width = 16, height = 10) {
  fname <<- paste("figs/", file, ".pdf", sep = "")
  pdf(fname, width = width / 2.54, height = height / 2.54, pointsize = 10)
  par(mgp = c(2.2, 0.45, 0), tcl = -0.4, mar = c(3.3, 3.6, 1.1, 1.1))
}
endpdf <- function() {
  crop::dev.off.crop(fname)
}
# Compute features
tourism_features <- tourism %>%
  features(Trips, feature_set(pkgs = "feasts"))
# Compute PCs
pcs <- tourism_features %>%
  select(-State, -Region, -Purpose) %>%
  prcomp(scale = TRUE) %>%
  broom::augment(tourism_features)
# Save some PC plots
savepdf("pca1", 18, 10)
pcs %>% ggplot(aes(x = .fittedPC1, y = .fittedPC2)) +
  geom_point() +
  theme(aspect.ratio = 1)
endpdf()
savepdf("pca2", 18, 10)
pcs %>% ggplot(aes(x = .fittedPC1, y = .fittedPC2, col = State)) +
  geom_point() +
  theme(aspect.ratio = 1)
endpdf()
savepdf("pca3", 18, 10)
pcs %>% ggplot(aes(x = .fittedPC1, y = .fittedPC2, col = Purpose)) +
  geom_point() +
  theme(aspect.ratio = 1)
endpdf()
# Find outliers
outliers <- pcs %>%
  filter(.fittedPC1 > 10)
savepdf("pca4", 18, 10)
pcs %>% ggplot(aes(x = .fittedPC1, y = .fittedPC2, col = Purpose)) +
  geom_point() +
  theme(aspect.ratio = 1) +
  geom_point(data = outliers, aes(x = .fittedPC1, y = .fittedPC2), col = "black", shape = 1, size = 3)
endpdf()
```

## Time series features
\fontsize{9}{9}\sf

```{r tourismfeatures, eval=FALSE, echo=TRUE}
tourism_features <- tourism %>%
  features(Trips, feature_set(pkgs = "feasts"))
```

\vspace*{-0.5cm}\fontsize{8}{8}\sf

```{r echo=FALSE}
tourism_features
```

\begin{textblock}{5}(9.6,1.5)
\begin{alertblock}{}\fontsize{10}{12}\sf
All features from the feasts package
\end{alertblock}
\end{textblock}

## Reduced feature space
\fontsize{9}{9}\sf

```{r pcatable, echo=TRUE}
pcs <- tourism_features %>%
  select(-State, -Region, -Purpose) %>%
  prcomp(scale = TRUE) %>%
  augment(tourism_features)
```

\vspace*{-0.5cm}\fontsize{8}{8}\sf

```{r echo=FALSE}
pcs
```

\begin{textblock}{5}(9.6,1.5)
\begin{alertblock}{}\fontsize{10}{12}\sf
Principal components based on all features from the feasts package
\end{alertblock}
\end{textblock}

## Feature manifolds
\fontsize{9}{9}\sf

\begin{textblock}{3.3}(.4,3)
\begin{alertblock}{}\fontsize{10}{12}\sf
Principal components based on all features from the feasts package
\end{alertblock}
\end{textblock}

```r
pcs %>% ggplot(aes(x=.fittedPC1, y=.fittedPC2)) +
  geom_point() + theme(aspect.ratio=1)
```

\placefig{4}{2.6}{height=6.4cm, width=12cm}{pca1}
\vspace*{10cm}

## Feature manifolds
\fontsize{9}{9}\sf

\begin{textblock}{3.3}(.4,3)
\begin{alertblock}{}\fontsize{10}{12}\sf
Principal components based on all features from the feasts package
\end{alertblock}
\end{textblock}

```r
pcs %>% ggplot(aes(x=.fittedPC1, y=.fittedPC2, col=State)) +
  geom_point() + theme(aspect.ratio=1)
```

\placefig{4}{2.6}{height=6.4cm, width=12cm}{pca2}
\vspace*{10cm}

## Feature manifolds
\fontsize{9}{9}\sf

\begin{textblock}{3.3}(.4,3)
\begin{alertblock}{}\fontsize{10}{12}\sf
Principal components based on all features from the feasts package
\end{alertblock}
\end{textblock}

```r
pcs %>% ggplot(aes(x=.fittedPC1, y=.fittedPC2, col=Purpose)) +
  geom_point() + theme(aspect.ratio=1)
```

\placefig{4}{2.6}{height=6.4cm, width=12cm}{pca3}
\vspace*{10cm}

## Anomaly detection using time series features
\fontsize{9}{9}\sf

\begin{textblock}{3.3}(.4,3)
\begin{alertblock}{}\fontsize{10}{12}\sf
Principal components based on all features from the feasts package
\end{alertblock}
\end{textblock}

```r
pcs %>% ggplot(aes(x=.fittedPC1, y=.fittedPC2, col=Purpose)) +
  geom_point() + theme(aspect.ratio=1)
```

\placefig{4}{2.6}{height=6.4cm, width=12cm}{pca4}
\vspace*{10cm}

## Anomaly detection using time series features
\fontsize{8}{8}\sf

```{r outliers2, fig.height=6, fig.width=10, out.width="100%", dependson='pca', echo=FALSE}
out <- outliers %>%
  left_join(tourism, by = c("State", "Region", "Purpose")) %>%
  mutate(
    Series = glue("{State}", "{Region}", "{Purpose}", .sep = "\n\n"),
    Series = as.character(Series)
  ) %>%
  select(Quarter, Series, Trips, .fittedPC2)
ordering <- out %>% 
  select(Series,.fittedPC2) %>%
  arrange(desc(.fittedPC2)) %>% 
  select(Series) %>%
  distinct(Series) %>%
  pull(Series)
out %>%
  mutate(Series = factor(Series, levels=ordering)) %>%
  select(Series, Quarter, Trips) %>%
  ggplot(aes(x = Quarter, y = Trips)) + geom_line() +
  facet_grid(Series ~ ., scales = "free_y") +
  ggtitle("Outlying time series in PC space")
```



# Yahoo server metrics

## Yahoo server metrics
\fontsize{13}{15}\sf\vspace*{-0.2cm}

  * Tens of thousands of time series collected at one-hour intervals over 1--2 months.
  * Consisting of several server metrics (e.g. CPU usage and paging views) from many server farms globally.
  * Aim: find unusual (anomalous) time series.

\placefig{0}{4.6}{width=16.5cm, height=200cm, trim=0 20 50 300, clip=TRUE}{serverfarm}
\vspace*{10cm}

## Yahoo server metrics
\vspace*{0.2cm}\par

```{r yahoodata, echo=FALSE}
yahoo <- tsfeatures::yahoo_data() %>%
  as_tsibble() %>%
  mutate(
    Time = hms::hms(
      day = trunc(index) - 1L,
      hour = as.integer((round(24 * (index - 1))) %% 24)
    )
  ) %>%
  as_tsibble(index = Time, key = key) %>%
  select(Time, key, value)
```

```{r yahoodataplot, echo=FALSE, dependson='yahoodata'}
yahoo %>%
  filter(
    Time < hms::hms(day = 30, hour = 0),
    key %in% sample(unique(key), 4)
  ) %>%
  ggplot(aes(x=Time, y=value, group=key)) +
  geom_line() +
  facet_grid(key ~ ., scales = "free_y") +
  scale_x_time(
    breaks = 24 * 60 * 60 * seq(0, 50, by = 2),
    labels = seq(0, 50, by = 2)) +
  xlab("Day")
```

## Yahoo server metrics
\fontsize{10}{11}\sf\vspace*{-0.2cm}

* **ACF1**: first order autocorrelation = $\text{Corr}(Y_t,Y_{t-1})$
* Strength of **trend** and **seasonality** based on STL
* Size of seasonal **peak** and **trough**
* Spectral **entropy**
* **Lumpiness**: variance of block variances (block size 24).
* **Spikiness**: variances of leave-one-out variances of STL remainders.
* **Level shift**: Maximum difference in trimmed means of consecutive moving windows of size 24.
* **Variance change**: Max difference in variances of consecutive moving windows of size 24.
* **Flat spots**: Discretize sample space into 10 equal-sized intervals. Find max run length in any interval.
* Number of **crossing points** of mean line.
 * **Kullback-Leibler score**:
      Maximum of $D_{KL}(P\|Q) = \int P(x)\ln P(x)/ Q(x) dx$
       where $P$ and $Q$ are estimated by kernel density estimators applied to
       consecutive windows of size 48.
* **Change index**: Time of maximum KL score

## Feature space
\fontsize{11}{11}\sf

```{r yahoo, fig.height=4, fig.width=4, dependson='yahoodata'}
yahoo_features <- left_join(
  yahoo %>% 
    features(value, features = list(
    mean = ~ mean(., na.rm = TRUE),
    var = ~ var(., na.rm = TRUE)
  )),
  yahoo %>% 
    features(scale(value), features = list(
      ~ feat_acf(.),
      ~ feat_spectral(.),
      ~ n_flat_spots(.),
      ~ n_crossing_points(.),
      ~ var_tiled_var(., .period = 24, .size = 24),
      ~ shift_level_max(., .period = 24, .size = 24),
      ~ shift_var_max(., .period = 24, .size = 24),
      ~ shift_kl_max(., .period = 24, .size = 48),
      ~ feat_stl(., .period = 24, s.window = "periodic", robust = TRUE)
    )),
    by = "key"
  ) %>%
  rename(lumpiness = var_tiled_var) %>%
  select(
    key, mean, var, acf1, trend_strength,
    seasonal_strength_24, linearity, curvature,
    seasonal_peak_24, seasonal_trough_24,
    spectral_entropy, lumpiness, spikiness,
    shift_level_max, shift_var_max,
    longest_flat_spot, n_crossing_points,
    shift_kl_max, shift_kl_index
  )
```

```{r yahoo2, dependson='yahoo'}
hwl_pca <- yahoo_features %>%
  select(-key) %>%
  na.omit() %>%
  prcomp(scale = TRUE) %>%
  augment(na.omit(yahoo_features))
hwl_pca %>%
  as_tibble() %>%
  ggplot(aes(x = .fittedPC1, y = .fittedPC2)) +
  geom_point()
```

## Feature space

```{r yahoobiplot, dependson='yahoo'}
yahoo_features %>%
  select(-key) %>%
  na.omit() %>%
  prcomp(scale = TRUE) %>%
  factoextra::fviz_pca_biplot(geom = "point", col.ind = "gray")
```

\only<2>{\begin{textblock}{4.8}(10.8,4.6)\fontsize{11}{11}\sf
\begin{alertblock}{\fontsize{11}{11}\sffamily What is ``anomalous''?}
\begin{itemize}\tightlist
\item We need a measure of the ``anomalousness'' of a time series.
\item Rank points based on their local density using a bivariate kernel density estimate.
\end{itemize}
\end{alertblock}
\end{textblock}}

## Finding weird time series
\fontsize{10}{10}\sf

```{r hdryahoo, dependson="yahoo"}
hdrcde::hdrscatterplot(hwl_pca$.fittedPC1, hwl_pca$.fittedPC2, noutliers = 5) + xlab(".fittedPC1") + ylab(".fittedPC2")
```

\begin{textblock}{4.8}(10.8,6.2)\fontsize{10}{10}\sf
\begin{alertblock}{\fontsize{10}{10}\sffamily Highest Density Regions}
\begin{itemize}\tightlist
\item Estimate using \texttt{hdrcde} package
\item Highlight outlying points as those with lowest density.
\end{itemize}
\end{alertblock}
\end{textblock}

# Feature-based forecasting

## M competition: 1982

\placefig{0.1}{1.4}{height=10.2cm,width=15cm}{M1}

\begin{textblock}{7.8}(7.8,2)
  \begin{block}{M-competition}
  \begin{itemize}
  \item 1001 series from demography, industry, economics.
  \item Annual, quarterly, monthly data.
  \item Anyone could submit forecasts.
  \item Multiple forecast measures used.
  \end{itemize}
  \end{block}
\end{textblock}

## M3 competition: 2000

\full{M3paper}

## M4 competition: 2018

\full{m4}

## M4 competition: 2018

 * 100,000 time series: yearly, quarterly, monthly, weekly, daily, hourly.
 * Point forecast and prediction intervals assessed.
 * Code must be public
 * 248 registrations, 50 submissions.

\pause

### Winning methods
 1. Hybrid of Recurrent Neural Network and Exponential Smoothing models
 2. FFORMA: Feature-based forecast combinations using xgboost to find weights

## Features used to select a forecasting model

\begin{textblock}{12}(0.1,1.1)\small
\begin{multicols}{2}
  \begin{itemize}\tightlist
    \item length
    \item strength of seasonality
    \item strength of trend
    \item linearity
    \item curvature
    \item spikiness
    \item stability
    \item lumpiness
    \item parameter estimates of Holt's linear trend method
    \item spectral entropy
    \item Hurst exponent
    \item nonlinearity
    \item parameter estimates of Holt-Winters' additive method
    \item unit root test statistics
    \item crossing points, flat spots
    \item peaks, troughs
    \item ACF and PACF based features - calculated on raw, differenced, and remainder series.
    \item ARCH/GARCH statistics and ACF of squared series and residuals.
    \end{itemize}
\end{multicols}
\end{textblock}

## Features used to select a forecasting model

\alert{Why these features?}

 * Hyndman, Wang and Laptev. “Large scale unusual time series detection” (ICDM 2015).
 * Kang, Hyndman & Smith-Miles. “Visualising forecasting algorithm performance using time series instance spaces” (IJF 2017).
 * Talagala, Hyndman and Athanasopoulos. “Meta-learning how to forecast time series” (2018).
 * Implemented in the **feasts** R package

## \fontsize{16}{16}\bf\sffamily FFORMS: Feature-based FORecast Model Selection

\only<1>{\full{fw1}}
\only<2>{\full{fw2}}
\only<3>{\full{fw3}}
\only<4>{\full{fw4}}
\only<5>{\full{fw5}}
\only<6>{\full{fw6}}
\only<7>{\full{fw7}}
\only<8>{\full{fw8}}
\only<9>{\full{fw9}}
\only<10>{\full{fw10}}
\only<11>{\full{fw11}}
\only<12>{\full{fw12}}
\only<13>{\full{fw13}}
\only<14>{\full{fw14}}

\vspace*{10cm}

## Application to M competition data

\begin{block}{Experiment 1}
\centering\small\tabcolsep=0.1cm
\begin{tabular}{lrrrrr}
                 & Source & Y      & Q      & M \\
\midrule
Observed series  & M1     & 181    & 203    & 617 \\
Simulated series &        & 362000 & 406000 & 123400 \\
New series       & M3     & 645    & 756    & 1428
\end{tabular}
\end{block}
\begin{block}{Experiment 2}
\centering\small\tabcolsep=0.1cm
\begin{tabular}{lrrrrr}
                 & Source & Y       & Q       & M \\
\midrule
Observed series  & M3     & 645     & 756     & 1428 \\
Simulated series &        & 1290000 & 1512000 & 285600 \\
New series       & M1     & 181     & 203     & 617
\end{tabular}
\end{block}

## Experiment 1: Distribution of time series in PCA space

\begin{textblock}{3}(1.3,1.4)
\colorbox{black}{\color{white}{observed - M1}}
\end{textblock}

\placefig{7}{1.3}{height=7.6cm, width=20cm}{observed.pdf}

## Experiment 1: Distribution of time series in PCA space

\begin{textblock}{3}(1.3,1.4)
\colorbox{black}{\color{white}{observed - M1}}
\colorbox{ao(english)}{simulated}
\end{textblock}

\placefig{7}{1.3}{height=7.6cm, width=20cm}{simulated.pdf}

## Experiment 1: Distribution of time series in PCA space

\begin{textblock}{3}(1.3,1.4)
\colorbox{black}{\color{white}{observed - M1}}
\colorbox{ao(english)}{simulated}
\colorbox{orange}{new - M3}
\end{textblock}
  
\placefig{7}{1.3}{height=7.6cm, width=20cm}{exp1pca-1.pdf}


## Experiment 2: Distribution of time series in PCA space

\begin{textblock}{3}(1.3,1.4)
\colorbox{black}{\color{white}{observed - M3}} 
\colorbox{ao(english)}{simulated} 
\colorbox{aureolin}{subset} 
\colorbox{orange}{new - M1}
\end{textblock}

\placefig{7}{1.3}{height=7.6cm, width=20cm}{exp2pca-1.pdf}

## Results: Yearly

```{r, message=FALSE, warning=FALSE, echo=FALSE}
method <- c(
  "RF-unbalanced", "RF-class priors", "auto.arima", "ets", "WN", "RW", "RWD", "Theta",
  "RF-unbalanced", "RF-class priors", "auto.arima", "ets", "WN", "RW", "RWD", "Theta"
)
Rank <- c(
  1.50, 1.50, 3.33, 5.00, 8.00, 7.00, 3.67, 6.00,
  3.50, 2.50, 5.83, 4.67, 9.00, 8.00, 1.00, 3.50
)
class <- c(0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1)
df <- data.frame(method = method, Rank = Rank, class = class)
ggplot(data = df, aes(x = method, y = Rank, fill = factor(class))) +
  geom_bar(position = "dodge", stat = "identity") +
  coord_flip() +
  scale_x_discrete(
    limits = c("WN", "RW", "auto.arima", "ets", "Theta", "RWD", "RF-class priors", "RF-unbalanced"),
    labels = c("WN", "RW", "auto.arima", "ets", "Theta", "RWD", "RF-class priors", "RF-unbalanced")
  ) + scale_fill_brewer(
    breaks = c(1, 0),
    labels = c("Experiment 1 (new: M3)", "Experiment 2 (new: M1)"),
    palette = "Set1"
  ) +
  theme(
    axis.title.y = element_blank(), legend.title = element_blank(),
    text = element_text(size = 20)
  )
```

## Results: Quarterly

```{r, message=FALSE, warning=FALSE, echo=FALSE}
library(ggplot2)
method <- c(
  "RF-unbalanced", "RF-class priors", "auto.arima", "ets", "WN", "RW", "RWD", "STL-AR", "Theta", "Snaive",
  "RF-unbalanced", "RF-class priors", "auto.arima", "ets", "WN", "RW", "RWD", "STL-AR", "Theta", "Snaive"
)
Rank <- c(
  1.00, 2.63, 5.25, 3.00, 10.00, 7.50, 5.38, 8.63, 3.88, 7.75, 2.25,
  3.13, 4.75, 3.75, 10.00, 7.00, 6.50, 8.34, 2.50, 6.75
)
class <- c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)
df <- data.frame(method = method, Rank = Rank, class = class)
ggplot(data = df, aes(x = method, y = Rank, fill = factor(class))) +
  geom_bar(position = "dodge", stat = "identity") +
  coord_flip() +
  scale_x_discrete(
    limits = c("WN", "RW", "RWD", "STL-AR", "Snaive", "auto.arima", "ets", "Theta", "RF-class priors", "RF-unbalanced"),
    labels = c("WN", "RW", "RWD", "STL-AR", "Snaive", "auto.arima", "ets", "Theta", "RF-class priors", "RF-unbalanced")
  ) + scale_fill_brewer(
    breaks = c(1, 0),
    labels = c("Experiment 1 (new: M3)", "Experiment 2 (new: M1)"),
    palette = "Set1"
  ) +
  theme(
    axis.title.y = element_blank(), legend.title = element_blank(),
    text = element_text(size = 20)
  )
```

## Results: Monthly

```{r, message=FALSE, warning=FALSE, echo=FALSE}
library(ggplot2)
method <- c(
  "RF-unbalanced", "RF-class priors", "auto.arima", "ets", "WN", "RW", "RWD", "STL-AR", "Theta", "Snaive",
  "RF-unbalanced", "RF-class priors", "auto.arima", "ets", "WN", "RW", "RWD", "STL-AR", "Theta", "Snaive"
)
Rank <- c(1.77, 2.83, 4.94, 3.44, 10.00, 7.25, 8.61, 7.38, 2.27, 6.47, 3.22, 2.00, 2.83, 2.72, 10.00, 8.03, 6.89, 7.89, 4.22, 7.19)
class <- c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1)
df <- data.frame(method = method, Rank = Rank, class = class)
ggplot(data = df, aes(x = method, y = Rank, fill = factor(class))) +
  geom_bar(position = "dodge", stat = "identity") +
  coord_flip() +
  scale_x_discrete(
    limits = c("WN", "RW", "RWD", "STL-AR", "Snaive", "auto.arima", "ets", "Theta", "RF-class priors", "RF-unbalanced"),
    labels = c("WN", "RW", "RWD", "STL-AR", "Snaive", "auto.arima", "ets", "Theta", "RF-class priors", "RF-unbalanced")
  ) + scale_fill_brewer(
    breaks = c(1, 0),
    labels = c("Experiment 1 (new: M3)", "Experiment 2 (new: M1)"),
    palette = "Set1"
  ) +
  theme(
    axis.title.y = element_blank(), legend.title = element_blank(),
    text = element_text(size = 20)
  )
```

## FFORMA: Feature-based FORecast Model Averaging

 * Like FFORMS but using gradient boosted trees (xgboost) rather than random forest.
 * Trained on temporal holdout version of M4 dataset, where size of test sets equal to required forecast horizons
 * Optimization criterion: forecast accuracy not classification accuracy.
 * Probability of each model being best is used to construct model weights for combination forecast.
 * 5 days computing time.

## FFORMA: Feature-based FORecast Model Averaging

### Models included

1. Naive
1. Seasonal naive
1. Random walk with drift
1. Theta method
1. ARIMA
1. ETS
1. TBATS
1. STL decomposition with AR for seasonally adjusted series
1. Neural network autoregression

## FFORMA: Feature-based FORecast Model Averaging

\placefig{1.9}{1.4}{width=12.4cm, trim=0 0 0 70, clip=true}{fforma_graphic}

\vspace*{4.5cm}\pause

### M4 competition results (based on average OWA)

```{r, results='asis'}
tribble(
    ~Place, ~OWA, ~Method,
    "1st", 0.821, NA,
    "2nd", 0.838, "(FFORMA)",
    "3rd", 0.841, NA
  ) %>%
  baretable(digits=3)
```


## Acknowledgments

\begin{textblock}{12.3}(2,1.2)
\begin{block}{}\fontsize{9}{10}\sf
\centering\begin{tabular}{p{2.6cm}p{2.3cm}p{2.9cm}l}
\includegraphics[height=2cm, width=10cm, keepaspectratio]{dilini} &
\includegraphics[height=2cm, width=10cm, keepaspectratio]{earowang}&
\includegraphics[height=2cm, width=10cm, keepaspectratio]{kate} &
\includegraphics[height=2cm, width=10cm, keepaspectratio]{george}\\
Dilini Talagala  & Earo Wang & Kate Smith-Miles & George Athanasopoulos \\
\includegraphics[height=2cm, width=10cm, keepaspectratio]{thiyanga} &
\includegraphics[height=2cm, width=10cm, keepaspectratio]{yanfei} &
\includegraphics[height=2cm, width=10cm, keepaspectratio]{mitch} &
\includegraphics[height=2cm, width=10cm, keepaspectratio]{pablo} \\
Thiyanga Talagala & Yanfei Kang & Mitchell O'Hara-Wild & Pablo Montero-Manso
 \end{tabular}
\end{block}
\end{textblock}

\begin{textblock}{8.3}(0.4,6.6)
\vspace*{0.3cm}
\begin{block}{}
\begin{itemize}
\item Packages: \textbf{tidyverts.org}
\item Textbook: \textbf{Otexts.com/fpp3}
\end{itemize}
\end{block}
\end{textblock}

\begin{textblock}{4.3}(11.4,6.6)
\begin{alertblock}{}
\href{https://robjhyndman.com}{\faicon{home} robjhyndman.com}\\
\href{https://twitter.com/robjhyndman}{\faicon{twitter} @robjhyndman}\\
\href{https://github.com/robjhyndman}{\faicon{github} @robjhyndman}
\end{alertblock}
\end{textblock}
